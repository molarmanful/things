# Proposal 1

- Conventional programming languages use "human-readable" language as an intermediate
  representation for programmers to both read and write code.
  - The syntactic patterns and conventions upon which these programming languages
    build has been subject to countless debates
    - Tabs vs. spaces, OO vs. FP, Python vs. C++, ... "should we sell user data?"
- But what if we freed ourselves from the constraints of written language?
  - What if we looked to other ways of interfacing with programs?
  - There already are instances of programming away from the norm.
    - Block-based
      - Scratch
    - Node-based
      - TouchDesigner
      - VFX: Blender, Redshift, Embergen
      - Unreal Engine
    - Esoteric
      - Piet
- We can go further.
- I propose a body-based programming language in which you:
  - Move, not write.
  - Feel, not read.
- Here, the development environment is not based around a text editor; rather,
  the programmer wears a suit.
  - Buttons, sliders, and sensors around the suit become the syntactic tokens.
  - Interacting with them creates instructions that the programmer can move,
    undo, or even group with other instructions to form compound instructions.
  - Feedback is haptic, auditory, and visual.
- The goal is to create a system that enables a fluent user to leverage the
  language's tactility/motions to program as effectively as they would in a
  text-based language.
- This programming system potentially has useful applications in performance
  art, accessibility, and education.
